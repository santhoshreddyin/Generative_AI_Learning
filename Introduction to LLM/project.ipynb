{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "TODO: In this cell, write an explanation of which dataset you have chosen and why it is appropriate for this task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "TODO: In the cells below, load your chosen dataset into a `pandas` dataframe with a column named `\"text\"`. This column should contain all of your text data, separated into at least 20 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2023 Fashion Trend: Red. Glossy red hues took ...\n",
       "1     2023 Fashion Trend: Cargo Pants. Utilitarian w...\n",
       "2     2023 Fashion Trend: Sheer Clothing. \"Bare it a...\n",
       "3     2023 Fashion Trend: Denim Reimagined. From dou...\n",
       "4     2023 Fashion Trend: Shine For The Daytime. The...\n",
       "                            ...                        \n",
       "77    If lime green isn't your vibe, rest assured th...\n",
       "78    \"As someone who can clearly (not fondly) remem...\n",
       "79    \"Combine this design shift with the fact that ...\n",
       "80    Thought party season ended at the stroke of mi...\n",
       "81    \"This season, we saw the revival of the bubble...\n",
       "Name: Trends, Length: 82, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "\n",
    "df = pd.read_csv('2023_fashion_trends.csv')\n",
    "\n",
    "df['Trends']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a595980",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "response = openai.embeddings.create(input = df[\"Trends\"], model=EMBEDDING_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9b850f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,data in enumerate(response.data):\n",
    "    df[\"embeddings\"][i] = data.embedding\n",
    "    #print(i,response.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4759e2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [-0.020776711404323578, -0.021952012553811073,...\n",
       "1     [-0.001848788931965828, -0.02892092987895012, ...\n",
       "2     [-0.010463573038578033, -0.019268615171313286,...\n",
       "3     [-0.015569761395454407, -0.005440722219645977,...\n",
       "4     [-0.004972496535629034, 0.0018217908218502998,...\n",
       "                            ...                        \n",
       "77    [-0.0027773624751716852, -0.01823779009282589,...\n",
       "78    [-0.014705789275467396, -0.006454960443079472,...\n",
       "79    [-0.020781872794032097, -0.025097381323575974,...\n",
       "80    [-0.019823411479592323, -0.022405004128813744,...\n",
       "81    [-0.030918996781110764, 0.002061266452074051, ...\n",
       "Name: embeddings, Length: 82, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"embeddings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53dcae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Query = openai.embeddings.create(input = \"What are the fashion trends for 2023?\", model=EMBEDDING_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "99aa77fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mQuery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "Query_embeddings = Query.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d3c1e325",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input vector should be 1-D.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01membeddings_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distances_from_embeddings\n\u001b[0;32m----> 3\u001b[0m distances \u001b[38;5;241m=\u001b[39m \u001b[43mdistances_from_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQuery_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQuery_embeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Learning/Udacity - Generative AI/Generative_AI_Learning/Introduction to LLM/embeddings_utils.py:151\u001b[0m, in \u001b[0;36mdistances_from_embeddings\u001b[0;34m(query_embedding, embeddings, distance_metric)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the distances between a query embedding and a list of embeddings.\"\"\"\u001b[39;00m\n\u001b[1;32m    144\u001b[0m distance_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m: spatial\u001b[38;5;241m.\u001b[39mdistance\u001b[38;5;241m.\u001b[39mcosine,\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL1\u001b[39m\u001b[38;5;124m\"\u001b[39m: spatial\u001b[38;5;241m.\u001b[39mdistance\u001b[38;5;241m.\u001b[39mcityblock,\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL2\u001b[39m\u001b[38;5;124m\"\u001b[39m: spatial\u001b[38;5;241m.\u001b[39mdistance\u001b[38;5;241m.\u001b[39meuclidean,\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinf\u001b[39m\u001b[38;5;124m\"\u001b[39m: spatial\u001b[38;5;241m.\u001b[39mdistance\u001b[38;5;241m.\u001b[39mchebyshev,\n\u001b[1;32m    149\u001b[0m }\n\u001b[1;32m    150\u001b[0m distances \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 151\u001b[0m     \u001b[43mdistance_metrics\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m embeddings\n\u001b[1;32m    153\u001b[0m ]\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m distances\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Learning/Udacity - Generative AI/Generative_AI_Learning/genai/lib/python3.12/site-packages/scipy/spatial/distance.py:694\u001b[0m, in \u001b[0;36mcosine\u001b[0;34m(u, v, w)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;124;03mCompute the Cosine distance between 1-D arrays.\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    690\u001b[0m \n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;66;03m# cosine distance is also referred to as 'uncentered correlation',\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;66;03m#   or 'reflective correlation'\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcorrelation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Learning/Udacity - Generative AI/Generative_AI_Learning/genai/lib/python3.12/site-packages/scipy/spatial/distance.py:626\u001b[0m, in \u001b[0;36mcorrelation\u001b[0;34m(u, v, w, centered)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03mCompute the correlation distance between two 1-D arrays.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    625\u001b[0m u \u001b[38;5;241m=\u001b[39m _validate_vector(u)\n\u001b[0;32m--> 626\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     w \u001b[38;5;241m=\u001b[39m _validate_weights(w)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Learning/Udacity - Generative AI/Generative_AI_Learning/genai/lib/python3.12/site-packages/scipy/spatial/distance.py:302\u001b[0m, in \u001b[0;36m_validate_vector\u001b[0;34m(u, dtype)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m u\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m u\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput vector should be 1-D.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Input vector should be 1-D."
     ]
    }
   ],
   "source": [
    "from embeddings_utils import distances_from_embeddings\n",
    "\n",
    "distances = distances_from_embeddings(Query_embeddings, Query_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n",
    "\n",
    "TODO: In the cells below, compose a custom query using your chosen dataset and retrieve results from an OpenAI `Completion` model. You may copy and paste any useful code from the course materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa13cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(role, question):\n",
    "   gptrole = {\"role\": \"system\", \"content\": role }\n",
    "   gptquestion = {\"role\": \"user\", \"content\": question}\n",
    "   messages = [gptrole, gptquestion]\n",
    "   print(messages)\n",
    "   response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages\n",
    "    )\n",
    "   return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "298fe9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'You are a helpful assistant'}, {'role': 'user', 'content': 'What are the fashion trends for 2023?'}]\n"
     ]
    }
   ],
   "source": [
    "answer = get_answer(\"You are a helpful assistant\", \"What are the fashion trends for 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33b4bed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Predicting fashion trends can be quite challenging as they are subject to change based on various factors such as influences from social media, celebrities, culture, and global events. However, some common trends that are expected to emerge in 2023 include:\\n\\n1. Sustainability and Eco-Friendly Fashion: With an increased focus on environmental issues, sustainable and eco-friendly fashion will continue to be a key trend in 2023. This includes the use of organic and recycled materials, as well as ethical production practices.\\n\\n2. Gender-Neutral Fashion: The rise of gender-neutral clothing and unisex styles is expected to continue in 2023, as the fashion industry becomes more inclusive and diverse.\\n\\n3. Minimalism and Classic Styles: Timeless pieces and minimalist designs are expected to be popular in 2023, as people seek longevity and versatility in their wardrobe choices.\\n\\n4. Bold Colors and Prints: Vibrant colors, bold prints, and patterns are expected to make a statement in 2023, adding a playful and expressive touch to outfits.\\n\\n5. Comfort and Functionality: Comfortable and functional clothing, such as athleisure wear and functional accessories, will continue to be popular as people prioritize comfort and versatility in their everyday clothing choices.\\n\\nRemember, trends are always evolving, so it's essential to choose styles that resonate with your personal taste and lifestyle.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string(\"tiktoken is great!\", \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"when was denim reimagined in fashion?\"},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13f2dcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'when was denim reimagined in fashion?'}]\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403f543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74280b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "TODO: In the cells below, demonstrate the performance of your custom query using at least 2 questions. For each question, show the answer from a basic `Completion` model query as well as the answer from your custom query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4901c850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7a093b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f646989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c07a54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
